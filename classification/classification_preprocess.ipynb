{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c218a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f3563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_yolov8_folder_for_preprocessing_with_images(\n",
    "    input_label_dir,\n",
    "    input_image_dir,\n",
    "    output_label_dir\n",
    "):\n",
    "    \"\"\"\n",
    "    Adjusts YOLOv8 label files in a folder based on preprocessing\n",
    "    (resize and crop), using the corresponding image to detect original shape.\n",
    "    \n",
    "    Args:\n",
    "        input_label_dir (str): Path to original YOLOv8 .txt files.\n",
    "        input_image_dir (str): Folder containing corresponding images.\n",
    "        output_label_dir (str): Destination path to save adjusted label files.\n",
    "    \"\"\"\n",
    "\n",
    "    target_resize_shape = (512, 512)\n",
    "    crop_y_start = 96\n",
    "    crop_x_start = 48\n",
    "    crop_x_end_offset = -48\n",
    "    final_width = target_resize_shape[1] - crop_x_start - abs(crop_x_end_offset)\n",
    "    final_height = target_resize_shape[0] - crop_y_start\n",
    "\n",
    "    os.makedirs(output_label_dir, exist_ok=True)\n",
    "    label_files = glob.glob(os.path.join(input_label_dir, \"*.txt\"))\n",
    "\n",
    "    for label_path in label_files:\n",
    "        base_name = os.path.splitext(os.path.basename(label_path))[0]\n",
    "        for ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
    "            image_path = os.path.join(input_image_dir, 'preprocess_' + base_name + ext)\n",
    "            print(image_path)\n",
    "            if os.path.exists(image_path):\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Image not found for label: {base_name}\")\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to read image: {image_path}\")\n",
    "            continue\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "\n",
    "        adjusted_lines = []\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                class_id, x_center, y_center, width, height = map(float, parts)\n",
    "\n",
    "                x_center_px = x_center * orig_w\n",
    "                y_center_px = y_center * orig_h\n",
    "                width_px = width * orig_w\n",
    "                height_px = height * orig_h\n",
    "\n",
    "                x_center_rs = x_center_px * (target_resize_shape[1] / orig_w)\n",
    "                y_center_rs = y_center_px * (target_resize_shape[0] / orig_h)\n",
    "                width_rs = width_px * (target_resize_shape[1] / orig_w)\n",
    "                height_rs = height_px * (target_resize_shape[0] / orig_h)\n",
    "\n",
    "                x_left = x_center_rs - width_rs / 2\n",
    "                y_top = y_center_rs - height_rs / 2\n",
    "\n",
    "                x_left_crop = x_left - crop_x_start\n",
    "                y_top_crop = y_top - crop_y_start\n",
    "\n",
    "                if x_left_crop < 0 or y_top_crop < 0 or \\\n",
    "                   x_left_crop + width_rs > final_width or \\\n",
    "                   y_top_crop + height_rs > final_height:\n",
    "                    continue\n",
    "                \n",
    "                x_center_crop = x_left_crop + width_rs / 2\n",
    "                y_center_crop = y_top_crop + height_rs / 2\n",
    "\n",
    "                x_center_final = x_center_crop / final_width\n",
    "                y_center_final = y_center_crop / final_height\n",
    "                width_final = width_rs / final_width\n",
    "                height_final = height_rs / final_height\n",
    "\n",
    "                if 0 <= x_center_final <= 1 and 0 <= y_center_final <= 1:\n",
    "                    adjusted_line = f\"{int(class_id)} {x_center_final:.6f} {y_center_final:.6f} {width_final:.6f} {height_final:.6f}\"\n",
    "                    adjusted_lines.append(adjusted_line)\n",
    "\n",
    "        save_path = os.path.join(output_label_dir, os.path.basename(label_path))\n",
    "        with open(save_path, 'w') as f_out:\n",
    "            f_out.write(\"\\n\".join(adjusted_lines))\n",
    "        print(f\"Adjusted: {label_path} → {save_path}\")\n",
    "\n",
    "\n",
    "def normalize_image(image_slice_np):\n",
    "    slice_float = image_slice_np.astype(np.float32)\n",
    "    min_val, max_val = np.min(slice_float), np.max(slice_float)\n",
    "    if max_val > min_val:\n",
    "        normalized_slice = (slice_float - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        normalized_slice = np.zeros_like(slice_float)\n",
    "    return normalized_slice\n",
    "\n",
    "def preprocess_and_crop_image_for_inference(image_path, pre_crop_shape=(512, 512), final_shape=(416, 416)):\n",
    "    try:\n",
    "        img_np = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img_np is None:\n",
    "            print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "            return None\n",
    "        \n",
    "        resized_slice = resize(img_np, pre_crop_shape, order=3, preserve_range=True, anti_aliasing=True)\n",
    "        normalized_slice = normalize_image(resized_slice)\n",
    "        \n",
    "        cropped_slice = normalized_slice[96:, 48:-48]\n",
    "        \n",
    "        if cropped_slice.shape != final_shape:\n",
    "            print(f\"Warning: Cropped shape {cropped_slice.shape} for {image_path} != expected {final_shape}.\")\n",
    "            cropped_slice = resize(cropped_slice, final_shape, order=3, preserve_range=True, anti_aliasing=True)\n",
    "        \n",
    "        final_tensor = np.expand_dims(cropped_slice, axis=-1) \n",
    "        final_tensor = np.expand_dims(final_tensor, axis=0)\n",
    "        return final_tensor.astype(np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_images_in_folder(image_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for subfolder in os.listdir(image_dir):\n",
    "        subfolder_path = os.path.join(image_dir, subfolder)\n",
    "        \n",
    "        if os.path.isdir(subfolder_path):\n",
    "            print(f\"Processing folder: {subfolder}\")\n",
    "\n",
    "            image_files = glob.glob(os.path.join(subfolder_path, '*.jpg')) + \\\n",
    "                          glob.glob(os.path.join(subfolder_path, '*.jpeg')) + \\\n",
    "                          glob.glob(os.path.join(subfolder_path, '*.png'))\n",
    "\n",
    "            if not image_files:\n",
    "                print(f\"No images found in folder {subfolder}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            for img_path in image_files:\n",
    "                output_subfolder = os.path.join(output_dir, subfolder)\n",
    "                os.makedirs(output_subfolder, exist_ok=True)\n",
    "\n",
    "                for img_path in image_files:\n",
    "                    input_tensor = preprocess_and_crop_image_for_inference(img_path)\n",
    "                    if input_tensor is None:\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        base_filename = os.path.basename(img_path)\n",
    "                        output_path = os.path.join(output_subfolder, f\"preprocessed_{base_filename}\")\n",
    "                        \n",
    "                        image_to_save = np.squeeze(input_tensor)\n",
    "\n",
    "                        image_to_save_uint8 = (image_to_save * 255.0).astype(np.uint8)\n",
    "\n",
    "                        cv2.imwrite(output_path, image_to_save_uint8)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error saving preprocessed image for {img_path}: {e}\")\n",
    "\n",
    "\n",
    "    print(\"Finished processing all images.\")\n",
    "\n",
    "def extract_id_from_filename(filename, source):\n",
    "    \"\"\"Extracts ID from filenames based on the source (image, mask, label).\"\"\"\n",
    "    name = Path(filename).stem\n",
    "    if source == 'image' or source == 'mask':\n",
    "        return name.split('_')[1].upper()\n",
    "    elif source == 'label':\n",
    "        return name.replace('-', '_').split('_')[0].upper()\n",
    "    else:\n",
    "        raise ValueError(\"Source must be one of ['image', 'mask', 'label']\")\n",
    "\n",
    "def find_bounding_boxes_contours(mask, min_area_threshold=100, padding=10):\n",
    "    if mask is None or mask.size == 0:\n",
    "        return []\n",
    "    if mask.dtype != np.uint8:\n",
    "        mask = mask.astype(np.uint8)\n",
    "    if mask.ndim == 3 and mask.shape[-1] == 1:\n",
    "        mask_2d = mask.squeeze(axis=-1)\n",
    "    elif mask.ndim == 2:\n",
    "        mask_2d = mask\n",
    "    else:\n",
    "        return []\n",
    "    contours, _ = cv2.findContours(mask_2d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = []\n",
    "    img_h, img_w = mask_2d.shape[:2]\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area >= min_area_threshold:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            pad_x = padding // 2\n",
    "            pad_y = padding // 2\n",
    "            x1p = max(0, x - pad_x)\n",
    "            y1p = max(0, y - pad_y)\n",
    "            x2_padded = min(img_w, (x + w) + (padding - pad_x))\n",
    "            y2_padded = min(img_h, (y + h) + (padding - pad_y))\n",
    "            final_w = x2_padded - x1p\n",
    "            final_h = y2_padded - y1p\n",
    "            if final_w > 0 and final_h > 0:\n",
    "                boxes.append((x1p, y1p, final_w, final_h))\n",
    "    boxes.sort(key=lambda b: (b[1], b[0]))\n",
    "    return boxes\n",
    "\n",
    "def boxes_overlap(boxA, boxB, threshold=0.1):\n",
    "    \"\"\"Check if two boxes overlap using IoU.\"\"\"\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])\n",
    "    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    if interArea == 0:\n",
    "        return False\n",
    "    boxAArea = boxA[2] * boxA[3]\n",
    "    boxBArea = boxB[2] * boxB[3]\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou > threshold\n",
    "\n",
    "def load_yolo_boxes(label_path, image_shape):\n",
    "    h, w = image_shape[:2]\n",
    "    boxes = []\n",
    "    if not os.path.exists(label_path):\n",
    "        return boxes\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            class_id, xc, yc, bw, bh = map(float, parts)\n",
    "            x = int((xc - bw / 2) * w)\n",
    "            y = int((yc - bh / 2) * h)\n",
    "            width = int(bw * w)\n",
    "            height = int(bh * h)\n",
    "            boxes.append((x, y, width, height, int(class_id)))\n",
    "    return boxes\n",
    "\n",
    "def get_middle_images_indices(num_images, middle_count=5):\n",
    "    \"\"\"Get the indices for the middle 'n' images.\"\"\"\n",
    "    if num_images < middle_count:\n",
    "        return None\n",
    "    \n",
    "    middle_start = (num_images - middle_count) // 2\n",
    "    middle_end = middle_start + middle_count\n",
    "    return list(range(middle_start, middle_end))\n",
    "\n",
    "def process_all(image_dir, label_dir, mask_dir, series_dir):\n",
    "    results = []\n",
    "    for folder in Path(series_dir).iterdir():\n",
    "        if not folder.is_dir():\n",
    "            continue\n",
    "        \n",
    "        image_id = folder.name.upper()\n",
    "        image_files = sorted(list(folder.glob(\"*.jpg\")))\n",
    "        num_images = len(image_files)\n",
    "        \n",
    "        middle_indices = get_middle_images_indices(num_images)\n",
    "        if middle_indices is None:\n",
    "            continue\n",
    "        \n",
    "        mask_path = next(Path(mask_dir).glob(f\"*_{image_id}_*.png\"), None)\n",
    "        if not mask_path or not mask_path.exists():\n",
    "            continue\n",
    "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            continue\n",
    "\n",
    "        gt_boxes = find_bounding_boxes_contours(mask)\n",
    "        gt_boxes = list({(x, y, w, h) for (x, y, w, h) in gt_boxes})\n",
    "\n",
    "        label_file = next(Path(label_dir).glob(f\"{image_id.replace('_', '-')}_*.txt\"), None)\n",
    "        if not label_file:\n",
    "            continue\n",
    "        sample_image = cv2.imread(str(image_files[middle_indices[len(middle_indices) // 2]]))\n",
    "        if sample_image is None:\n",
    "            continue\n",
    "        yolo_boxes = load_yolo_boxes(str(label_file), sample_image.shape)\n",
    "\n",
    "        for gt_box in gt_boxes:\n",
    "            for yolo_box in yolo_boxes:\n",
    "                if boxes_overlap(gt_box, yolo_box[:4]):\n",
    "                    cropped_images = []\n",
    "                    for index in middle_indices:\n",
    "                        image = cv2.imread(str(image_files[index]))\n",
    "                        x, y, w, h = gt_box\n",
    "                        x-=5\n",
    "                        y-=5\n",
    "                        w+=10\n",
    "                        h+=10\n",
    "                        cropped = image[y:y+h, x:x+w]\n",
    "                        cropped_images.append(cropped)\n",
    "\n",
    "                    label = 0 if yolo_box[4] % 2 == 0 else 1\n",
    "                    results.append({\n",
    "                        \"ID\": image_id,\n",
    "                        \"IMG1\": cropped_images[0],\n",
    "                        \"IMG2\": cropped_images[1],\n",
    "                        \"IMG3\": cropped_images[2],\n",
    "                        \"IMG4\": cropped_images[3],\n",
    "                        \"IMG5\": cropped_images[4],\n",
    "                        \"Label\": label\n",
    "                    })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def save_cropped_images_and_labels(df, output_dir):\n",
    "    \"\"\"\n",
    "    Saves cropped images from columns IMG1–IMG5 using filename pattern: ID_index_IMGx.jpg,\n",
    "    and writes a CSV mapping filenames to labels.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with columns 'ID', 'Label', 'IMG1'..'IMG5'\n",
    "        output_dir (str): Directory where images and labels.csv will be saved\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    labels_list = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        image_id = row[\"ID\"]\n",
    "        label = row[\"Label\"]\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            img_col = f\"IMG{i}\"\n",
    "            image = row[img_col]\n",
    "            if image is None or image.size == 0:\n",
    "                continue\n",
    "\n",
    "            filename = f\"{image_id}_{idx+1}_IMG{i}.jpg\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "            cv2.imwrite(filepath, image)\n",
    "\n",
    "            labels_list.append({\n",
    "                \"filename\": filename,\n",
    "                \"label\": label\n",
    "            })\n",
    "\n",
    "    labels_df = pd.DataFrame(labels_list)\n",
    "    labels_df.to_csv(os.path.join(output_dir, \"labels.csv\"), index=False)\n",
    "    print(f\"Saved {len(labels_list)} images and labels to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94773ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'C:/Users/danaa/Downloads/JUH_segmentation_output/train_preprocessed'\n",
    "label_dir = 'C:/Users/danaa/Desktop/uni/GP 2/Full Annotated Data/train/labels'\n",
    "mask_dir = 'C:/Users/danaa/Downloads/JUH_segmentation_output/train_masks'\n",
    "\n",
    "adjust_yolov8_folder_for_preprocessing_with_images(\n",
    "    input_label_dir=label_dir,\n",
    "    input_image_dir=image_dir,\n",
    "    output_label_dir=\"C:/Users/danaa/Downloads/adjusted labels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f5c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = \"C:/Users/danaa/Desktop/Sagittal\"\n",
    "output_directory = \"C:/Users/danaa/Desktop/preprocessed series\"\n",
    "\n",
    "preprocess_images_in_folder(image_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f844e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dir = 'C:/Users/danaa/Desktop/preprocessed series'\n",
    "label_dir = \"C:/Users/danaa/Downloads/adjusted labels\"\n",
    "image_dir = 'C:/Users/danaa/Downloads/JUH_segmentation_output/train_preprocessed'\n",
    "mask_dir = 'C:/Users/danaa/Downloads/JUH_segmentation_output/train_masks'\n",
    "\n",
    "df = process_all(image_dir, label_dir, mask_dir, series_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6e664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 6700 images and labels to seg cropped\n"
     ]
    }
   ],
   "source": [
    "output_path = \"seg cropped\"\n",
    "save_cropped_images_and_labels(df, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3fa5f",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b13013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_paths_and_labels(path):\n",
    "    image_files = [f for f in os.listdir(path) if f.endswith('.jpg')]\n",
    "    labels_file = os.path.join(path, \"labels.csv\")\n",
    "    labels_df = pd.read_csv(labels_file)\n",
    "\n",
    "    label_dict = dict(zip(labels_df['filename'], labels_df['label']))\n",
    "\n",
    "    id_groups = {}\n",
    "\n",
    "    for img_file in image_files:\n",
    "        id_num = '_'.join(img_file.split('_')[:2])\n",
    "\n",
    "        if id_num not in id_groups:\n",
    "            id_groups[id_num] = {}\n",
    "\n",
    "        img_idx = int(img_file.split('_')[2].split('.')[0].replace('IMG', ''))\n",
    "        img_path = os.path.join(path, img_file)\n",
    "\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        id_groups[id_num][f\"IMG{img_idx}\"] = img\n",
    "\n",
    "    data = []\n",
    "    for id_num, images in id_groups.items():\n",
    "        row = {'ID': id_num, 'Label': label_dict.get(f\"{id_num}_IMG1.jpg\", None)}\n",
    "        row.update(images)\n",
    "        data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "def visualize_image(image):\n",
    "    \"\"\"\n",
    "    Visualizes a 2D numpy array image.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): 2D numpy array representing the image to be visualized.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def preprocess(df):\n",
    "    processed_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ID = row[\"ID\"]\n",
    "        Label = row[\"Label\"]\n",
    "        processed_images = [img / 255.0 for img in row[2:]]\n",
    "        processed_images = [cv2.resize(img, (80, 40)) for img in processed_images]\n",
    "        processed_data.append([ID] + [Label] + processed_images)\n",
    "\n",
    "    return pd.DataFrame(processed_data, columns=df.columns)\n",
    "\n",
    "\n",
    "\n",
    "def split_df_by_patient(df, test_size=0.2, val_size=0.2, random_state=42):\n",
    "    df['PatientID'] = df['ID'].apply(lambda x: x.replace('-', '_').split('_')[0])\n",
    "    unique_patients = df['PatientID'].unique()\n",
    "\n",
    "    train_patients, test_patients = train_test_split(\n",
    "        unique_patients, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    train_patients_final, val_patients = train_test_split(\n",
    "        train_patients, test_size=val_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    train_df = df[df['PatientID'].isin(train_patients_final)].reset_index(drop=True)\n",
    "    val_df = df[df['PatientID'].isin(val_patients)].reset_index(drop=True)\n",
    "    test_df = df[df['PatientID'].isin(test_patients)].reset_index(drop=True)\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def rotate(img, angle):\n",
    "    (h, w) = img.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated_image = cv2.warpAffine(img, rotation_matrix, (w, h))\n",
    "    return rotated_image\n",
    "\n",
    "def add_noise(image, mean=0, sigma=0.01):\n",
    "    noise = np.random.normal(mean, sigma, image.shape).astype('float64')\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return noisy_image\n",
    "\n",
    "def horizontal_flip(image):\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    return flipped_image\n",
    "\n",
    "\n",
    "def augmentation(df):\n",
    "\n",
    "    rotations_r = pd.DataFrame(columns=['ID', 'Label', 'IMG1', 'IMG2', 'IMG3', 'IMG4', 'IMG5'])\n",
    "    rotations_l = pd.DataFrame(columns=['ID', 'Label', 'IMG1', 'IMG2', 'IMG3', 'IMG4', 'IMG5'])\n",
    "    noise = pd.DataFrame(columns=['ID', 'Label', 'IMG1', 'IMG2', 'IMG3', 'IMG4', 'IMG5'])\n",
    "    flip = pd.DataFrame(columns=['ID', 'Label', 'IMG1', 'IMG2', 'IMG3', 'IMG4', 'IMG5'])\n",
    "\n",
    "    for _,i in df.iterrows():\n",
    "\n",
    "        if i['Label']==0:\n",
    "            continue\n",
    "\n",
    "        angle = random.randint(5, 15)\n",
    "        rotations_r.loc[len(rotations_r)] = [i['ID'], i['Label'], \n",
    "                                               rotate(i['IMG1'], angle), rotate(i['IMG2'], angle), rotate(i['IMG3'], angle),\n",
    "                                               rotate(i['IMG4'], angle), rotate(i['IMG5'], angle)] \n",
    "        \n",
    "    for _,i in df.iterrows():\n",
    "\n",
    "        flip.loc[len(flip)] = [i['ID'], i['Label'], \n",
    "                                               horizontal_flip(i['IMG1']), horizontal_flip(i['IMG2']), horizontal_flip(i['IMG3']),\n",
    "                                               horizontal_flip(i['IMG4']), horizontal_flip(i['IMG5'])] \n",
    "        \n",
    "        \n",
    "    for _,i in df.iterrows():\n",
    "\n",
    "\n",
    "        angle = random.randint(-15, -5)\n",
    "        rotations_l.loc[len(rotations_l)] = [i['ID'], i['Label'], \n",
    "                                            rotate(i['IMG1'], angle), rotate(i['IMG2'], angle), rotate(i['IMG3'], angle),\n",
    "                                            rotate(i['IMG4'], angle), rotate(i['IMG5'], angle)] \n",
    "        \n",
    "\n",
    "    for _,i in df.iterrows():\n",
    "\n",
    "        if i['Label']==0:\n",
    "            continue\n",
    "\n",
    "        noise.loc[len(noise)] = [i['ID'], i['Label'], \n",
    "                                add_noise(i['IMG1'], 0, 0.02), add_noise(i['IMG2'], 0, 0.02), add_noise(i['IMG3'], 0, 0.02),\n",
    "                                add_noise(i['IMG4'], 0, 0.02), add_noise(i['IMG5'], 0, 0.02)] \n",
    "        \n",
    "    for _,i in df.iterrows():\n",
    "\n",
    "        noise.loc[len(noise)] = [i['ID'], i['Label'], \n",
    "                                add_noise(i['IMG1']), add_noise(i['IMG2']), add_noise(i['IMG3']),\n",
    "                                add_noise(i['IMG4']), add_noise(i['IMG5'])] \n",
    "        \n",
    "\n",
    "    df = pd.concat([df, rotations_l], axis=0, ignore_index=True)\n",
    "    df = pd.concat([df, rotations_r], axis=0, ignore_index=True)\n",
    "    df = pd.concat([df, noise], axis=0, ignore_index=True)\n",
    "    df = pd.concat([df, flip], axis=0, ignore_index=True)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c012d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_path = \"seg cropped\"\n",
    "df = read_image_paths_and_labels(cropped_path)\n",
    "\n",
    "print(len(df))\n",
    "visualize_image(df.iloc[100]['IMG1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess(df)\n",
    "\n",
    "visualize_image(df.iloc[100]['IMG1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc81b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_df_by_patient(df)\n",
    "\n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fae3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = augmentation(train_df)\n",
    "val_df = augmentation(val_df)\n",
    "test_df = augmentation(test_df)\n",
    "\n",
    "print(len(train_df))\n",
    "print(train_df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95299919",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"C:/Users/danaa/Desktop/Full Data/train\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "id_counts = {}\n",
    "unique_ids = []\n",
    "\n",
    "for original_id in train_df['ID']:\n",
    "    count = id_counts.get(original_id, 0) + 1\n",
    "    id_counts[original_id] = count\n",
    "    unique_ids.append(f\"{original_id}_{count}\")\n",
    "\n",
    "train_df['Unique_ID'] = unique_ids\n",
    "\n",
    "label_records = []\n",
    "img_cols = ['IMG1', 'IMG2', 'IMG3', 'IMG4', 'IMG5']\n",
    "\n",
    "def convert_to_uint8(array):\n",
    "    if array.dtype != np.uint8:\n",
    "        array = np.clip(array, 0, 1) * 255\n",
    "        array = array.astype(np.uint8)\n",
    "    return array\n",
    "\n",
    "for idx, row in train_df.iterrows():\n",
    "    uid = row['Unique_ID']\n",
    "    label = row['Label']\n",
    "    for col in img_cols:\n",
    "        img_array = row[col]\n",
    "        if isinstance(img_array, np.ndarray):\n",
    "            img_array = convert_to_uint8(img_array)\n",
    "            image = Image.fromarray(img_array)\n",
    "            filename = f\"{uid}_{col}.jpg\"\n",
    "            image.save(os.path.join(save_dir, filename))\n",
    "            label_records.append({'filename': filename, 'label': label})\n",
    "\n",
    "label_df = pd.DataFrame(label_records)\n",
    "label_df.to_csv(os.path.join(save_dir, \"labels.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b13f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"C:/Users/danaa/Desktop/Full Data/test\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "id_counts = {}\n",
    "unique_ids = []\n",
    "\n",
    "for original_id in test_df['ID']:\n",
    "    count = id_counts.get(original_id, 0) + 1\n",
    "    id_counts[original_id] = count\n",
    "    unique_ids.append(f\"{original_id}_{count}\")\n",
    "\n",
    "test_df['Unique_ID'] = unique_ids\n",
    "\n",
    "label_records = []\n",
    "img_cols = ['IMG1', 'IMG2', 'IMG3', 'IMG4', 'IMG5']\n",
    "\n",
    "def convert_to_uint8(array):\n",
    "    if array.dtype != np.uint8:\n",
    "        array = np.clip(array, 0, 1) * 255\n",
    "        array = array.astype(np.uint8)\n",
    "    return array\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    uid = row['Unique_ID']\n",
    "    label = row['Label']\n",
    "    for col in img_cols:\n",
    "        img_array = row[col]\n",
    "        if isinstance(img_array, np.ndarray):\n",
    "            img_array = convert_to_uint8(img_array)\n",
    "            image = Image.fromarray(img_array)\n",
    "            filename = f\"{uid}_{col}.jpg\"\n",
    "            image.save(os.path.join(save_dir, filename))\n",
    "            label_records.append({'filename': filename, 'label': label})\n",
    "\n",
    "label_df = pd.DataFrame(label_records)\n",
    "label_df.to_csv(os.path.join(save_dir, \"labels.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23737e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"C:/Users/danaa/Desktop/Full Data/val\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "id_counts = {}\n",
    "unique_ids = []\n",
    "\n",
    "for original_id in val_df['ID']:\n",
    "    count = id_counts.get(original_id, 0) + 1\n",
    "    id_counts[original_id] = count\n",
    "    unique_ids.append(f\"{original_id}_{count}\")\n",
    "\n",
    "val_df['Unique_ID'] = unique_ids\n",
    "\n",
    "label_records = []\n",
    "img_cols = ['IMG1', 'IMG2', 'IMG3', 'IMG4', 'IMG5']\n",
    "\n",
    "def convert_to_uint8(array):\n",
    "    if array.dtype != np.uint8:\n",
    "        array = np.clip(array, 0, 1) * 255\n",
    "        array = array.astype(np.uint8)\n",
    "    return array\n",
    "\n",
    "for idx, row in val_df.iterrows():\n",
    "    uid = row['Unique_ID']\n",
    "    label = row['Label']\n",
    "    for col in img_cols:\n",
    "        img_array = row[col]\n",
    "        if isinstance(img_array, np.ndarray):\n",
    "            img_array = convert_to_uint8(img_array)\n",
    "            image = Image.fromarray(img_array)\n",
    "            filename = f\"{uid}_{col}.jpg\"\n",
    "            image.save(os.path.join(save_dir, filename))\n",
    "            label_records.append({'filename': filename, 'label': label})\n",
    "\n",
    "label_df = pd.DataFrame(label_records)\n",
    "label_df.to_csv(os.path.join(save_dir, \"labels.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
